{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "#from pyAudioAnalysis import audioSegmentation as aS\n",
    "import wave\n",
    "import unicodedata as un\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import pdb\n",
    "import ipdb\n",
    "import array as ar\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import IPython\n",
    "\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import sgd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute spectogram of each audio\n",
    "\n",
    "SR = 22050\n",
    "def get_short_time_fourier_transform(soundwave):\n",
    "    return librosa.stft(soundwave, n_fft=256)\n",
    "\n",
    "def short_time_fourier_transform_amplitude_to_db(stft):\n",
    "    return librosa.amplitude_to_db(stft)\n",
    "\n",
    "def soundwave_to_np_spectogram(soundwave):\n",
    "    step1 = get_short_time_fourier_transform(soundwave)\n",
    "    step2 = short_time_fourier_transform_amplitude_to_db(step1)\n",
    "    step3 = step2/100\n",
    "    return step3\n",
    "\n",
    "def inspect_data(sound):\n",
    "#    plt.figure()\n",
    "#    plt.plot(sound)\n",
    "#    IPython.display.display(IPython.display.Audio(sound, rate=SR))\n",
    "    a = get_short_time_fourier_transform(sound)\n",
    "    Xdb = short_time_fourier_transform_amplitude_to_db(a)\n",
    "#    plt.figure()   \n",
    "#    plt.imshow(Xdb)    \n",
    "#    plt.show()\n",
    "#    print (Xdb.shape)\n",
    "#    print(\"Length per sample: %d, shape of spectogram: %s, max: %f min: %f\" % (len(sound), str(Xdb.shape), Xdb.max(), Xdb.min()))\n",
    "    return Xdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir archivos de audio y segmentar por segmento de tiempo.\n",
    "#Exportar los segmentos a otra carpeta para su posterior analisis\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "number_list_train = ['']\n",
    "number_list_test = ['']\n",
    "file_count = 107\n",
    "file_count2 = 35\n",
    "input_array_train = ['']\n",
    "phq8_array_train = ['']\n",
    "input_array_train *= file_count\n",
    "phq8_array_train *= file_count\n",
    "number_list_train *= file_count\n",
    "input_array_test = ['']\n",
    "phq8_array_test = ['']\n",
    "input_array_test *= file_count2\n",
    "phq8_array_test *= file_count2\n",
    "number_list_test *= file_count2\n",
    "number = 0\n",
    "\n",
    "    \n",
    "data = open('C:/Users/Fran/Desktop/Database/datos1.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_train[i] = w\n",
    "    number_list_train[i] = number\n",
    "    phq8_array_train[i] = mylist[1]\n",
    "    newAudio = w[60000:80000]\n",
    "    newAudio.export('C:/Users/Fran/Desktop/Database_procesada_train/' + str(number) + '.wav', format=\"wav\")\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "data1 = open('C:/Users/Fran/Desktop/Database/datos2_dev.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data1:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_test[i] = w\n",
    "    number_list_test[i] = number\n",
    "    phq8_array_test[i] = mylist[1]\n",
    "    newAudio = w[60000:80000]\n",
    "    newAudio.export('C:/Users/Fran/Desktop/Database_procesada_test/' + str(number) + '.wav', format=\"wav\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fran\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:960: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  warnings.warn('amplitude_to_db was called on complex input so phase '\n"
     ]
    }
   ],
   "source": [
    "#Spectograms of each segmented audio\n",
    "\n",
    "i = 0\n",
    "Xdb_train = ['']\n",
    "Xdb_train *= file_count\n",
    "\n",
    "Xdb_test = ['']\n",
    "Xdb_test *= file_count2\n",
    "\n",
    "for audio_train in number_list_train:\n",
    "    X, sr = librosa.load('C:/Users/Fran/Desktop/Database_procesada_train/' + str(audio_train) + '.wav')\n",
    "    Xdb_train[i] = inspect_data(X)\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "\n",
    "for audio_train in number_list_test:\n",
    "    X, sr = librosa.load('C:/Users/Fran/Desktop/Database_procesada_test/' + str(audio_train) + '.wav')\n",
    "    Xdb_test[i] = inspect_data(X)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b5a04f69e8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xdb_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "phq8_array_train = keras.utils.to_categorical(phq8_array_train, num_classes)\n",
    "phq8_array_test = keras.utils.to_categorical(phq8_array_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 127, 6889, 32)     320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 3444, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 3442, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 1721, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 1719, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 859, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 857, 256)      295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 428, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 428, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 657408)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               84148352  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 84,536,450\n",
      "Trainable params: 84,536,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Red neuronal\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(129,6891,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdb_train_array = np.ndarray(shape = (107,129,6891))\n",
    "Xdb_test_array = np.ndarray(shape = (35,129,6891))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for train in Xdb_train:\n",
    "    Xdb_train_array[i] = train\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "for train in Xdb_test:\n",
    "    Xdb_test_array[i] = train\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdb_train_array = Xdb_train_array.reshape(Xdb_train_array.shape[0], 129, 6891, 1)\n",
    "Xdb_test_array = Xdb_test_array.reshape(Xdb_test_array.shape[0], 129, 6891, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 129, 6891, 1)\n",
      "(35, 129, 6891, 1)\n"
     ]
    }
   ],
   "source": [
    "print (Xdb_train_array.shape)\n",
    "print (Xdb_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107 samples, validate on 35 samples\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 161s 2s/step - loss: 10.9257 - acc: 0.2991 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 128s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 127s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 126s 1s/step - loss: 11.5990 - acc: 0.2804 - val_loss: 10.5919 - val_acc: 0.3429\n",
      "Test loss: 10.591891261509486\n",
      "Test accuracy: 0.34285714285714286\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xdb_train_array, phq8_array_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(Xdb_test_array, phq8_array_test))\n",
    "score = model.evaluate(Xdb_test_array, phq8_array_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediccion = model.predict(Xdb_test, batch_size=batch_size, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
