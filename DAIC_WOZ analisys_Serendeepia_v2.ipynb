{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, LSTM, Bidirectional\n",
    "from keras.optimizers import sgd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute spectogram of each audio\n",
    "\n",
    "SR = 22050\n",
    "def get_short_time_fourier_transform(soundwave):\n",
    "    return librosa.stft(soundwave, n_fft=256)\n",
    "\n",
    "def short_time_fourier_transform_amplitude_to_db(stft):\n",
    "    return librosa.amplitude_to_db(stft)\n",
    "\n",
    "def soundwave_to_np_spectogram(soundwave):\n",
    "    step1 = get_short_time_fourier_transform(soundwave)\n",
    "    step2 = short_time_fourier_transform_amplitude_to_db(step1)\n",
    "    step3 = step2/100\n",
    "    return step3\n",
    "\n",
    "def inspect_data(sound):\n",
    "#    plt.figure()\n",
    "#    plt.plot(sound)\n",
    "#    IPython.display.display(IPython.display.Audio(sound, rate=SR))\n",
    "    a = get_short_time_fourier_transform(sound)\n",
    "    Xdb = short_time_fourier_transform_amplitude_to_db(a)\n",
    "#    plt.figure()   \n",
    "#    plt.imshow(Xdb)    \n",
    "#    plt.show()\n",
    "#    print (Xdb.shape)\n",
    "#    print(\"Length per sample: %d, shape of spectogram: %s, max: %f min: %f\" % (len(sound), str(Xdb.shape), Xdb.max(), Xdb.min()))\n",
    "    return Xdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de las variables necesarias para la ejecucion del codigo\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "number_list_train = ['']\n",
    "number_list_test = ['']\n",
    "file_count = 107\n",
    "file_count2 = 35\n",
    "input_array_train = ['']\n",
    "phq8_array_train = ['']\n",
    "input_array_train *= file_count\n",
    "phq8_array_train *= file_count\n",
    "number_list_train *= file_count\n",
    "input_array_test = ['']\n",
    "phq8_array_test = ['']\n",
    "input_array_test *= file_count2\n",
    "phq8_array_test *= file_count2\n",
    "number_list_test *= file_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir archivos de audio y segmentar por segmento de tiempo.\n",
    "#Exportar los segmentos a otra carpeta para su posterior analisis\n",
    "\n",
    "\n",
    "number = 0\n",
    "\n",
    "l = 0\n",
    "m = 0\n",
    "      \n",
    "data = open('C:/Users/Fran/Desktop/Database/datos1.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    df = pd.read_csv('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' \n",
    "                     + str(number) + '_TRANSCRIPT.csv', header=0)\n",
    "    while i < len (df):\n",
    "        a = df.iloc[i].str.split()\n",
    "        if a[0][2] == 'Participant' and j == 0: \n",
    "            newAudio = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' \n",
    "                                             + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "            t1 = int(float(a[0][0]) * 1000)\n",
    "            t2 = int(float(a[0][1]) * 1000)\n",
    "            newAudio = newAudio[t1:t2]\n",
    "            newAudio.export('C:/Users/Fran/Desktop/prueba/' + str(number) + '.wav', format=\"wav\")\n",
    "            j = 1\n",
    "        elif a[0][2] == 'Participant':\n",
    "            \n",
    "            newAudio = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' \n",
    "                                             + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "            t1 = int(float(a[0][0]) * 1000)\n",
    "            t2 = int(float(a[0][1]) * 1000)\n",
    "            newAudio = newAudio[t1:t2]\n",
    "            newAudio.export('C:/Users/Fran/Desktop/prueba/' + str(number) + 'segmento.wav', format=\"wav\")\n",
    "            sound1 = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba/' + str(number) + '.wav')\n",
    "            sound2 = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba/' + str(number) + 'segmento.wav')\n",
    "\n",
    "            combined_sounds = sound1 + sound2\n",
    "            combined_sounds.export('C:/Users/Fran/Desktop/prueba/' + str(number) + '.wav', format=\"wav\")\n",
    "        i += 1\n",
    "             \n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_train[l] = w\n",
    "    number_list_train[l] = number\n",
    "    phq8_array_train[l] = mylist[1]\n",
    "    l += 1\n",
    "    j = 0\n",
    "    i = 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir archivos de audio y segmentar por segmento de tiempo.\n",
    "#Exportar los segmentos a otra carpeta para su posterior analisis\n",
    "\n",
    "i = 0\n",
    "l = 0\n",
    "m = 0\n",
    "data1 = open('C:/Users/Fran/Desktop/Database/datos2_dev.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data1:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    df = pd.read_csv('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' \n",
    "                     + str(number) + '_TRANSCRIPT.csv', header=0)\n",
    "    while i < len (df):\n",
    "        a = df.iloc[i].str.split()\n",
    "        if a[0][2] == 'Participant' and j == 0: \n",
    "            newAudio = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' \n",
    "                                             + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "            t1 = int(float(a[0][0]) * 1000)\n",
    "            t2 = int(float(a[0][1]) * 1000)\n",
    "            newAudio = newAudio[t1:t2]\n",
    "            newAudio.export('C:/Users/Fran/Desktop/prueba_test/' + str(number) + '.wav', format=\"wav\")\n",
    "            j = 1\n",
    "        elif a[0][2] == 'Participant':\n",
    "            \n",
    "            newAudio = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' \n",
    "                                             + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "            t1 = int(float(a[0][0]) * 1000)\n",
    "            t2 = int(float(a[0][1]) * 1000)\n",
    "            newAudio = newAudio[t1:t2]\n",
    "            newAudio.export('C:/Users/Fran/Desktop/prueba_test/' + str(number) + 'segmento.wav', format=\"wav\")\n",
    "            sound1 = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba_test/' + str(number) + '.wav')\n",
    "            sound2 = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba_test/' + str(number) + 'segmento.wav')\n",
    "\n",
    "            combined_sounds = sound1 + sound2\n",
    "            combined_sounds.export('C:/Users/Fran/Desktop/prueba_test/' + str(number) + '.wav', format=\"wav\")\n",
    "        i += 1\n",
    "             \n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_test[l] = w\n",
    "    number_list_test[l] = number\n",
    "    phq8_array_test[l] = mylist[1]\n",
    "    l += 1\n",
    "    j = 0\n",
    "    i = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion de arrays, que seran usados despues para el entranamiento del modelo y creacion de espectogramas\n",
    "\n",
    "l = 0\n",
    "data = open('C:/Users/Fran/Desktop/Database/datos1.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_train[l] = w\n",
    "    number_list_train[l] = number\n",
    "    phq8_array_train[l] = mylist[1]\n",
    "    l += 1\n",
    "    \n",
    "l = 0\n",
    "data1 = open('C:/Users/Fran/Desktop/Database/datos2_dev.txt', 'r', encoding='utf-8-sig')\n",
    "for line in data1:\n",
    "    mylist = line.split(',')\n",
    "    number = mylist[0]\n",
    "    w = AudioSegment.from_wav('C:/Users/Fran/Desktop/Database/' + str(number) + '_P/' + str(number) + '_AUDIO.wav')\n",
    "    input_array_test[l] = w\n",
    "    number_list_test[l] = number\n",
    "    phq8_array_test[l] = mylist[1]\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de la longitud de cada audio para en un futuro poder mover la ventana de tiempo \n",
    "#del minimo al maximo unos determinados segundos, de momento esta informacion no se utiliza\n",
    "#y se calcula el segmento de audio con un tiempo fijo\n",
    "\n",
    "len_list_train = ['']\n",
    "len_list_test = ['']\n",
    "len_list_train *= file_count\n",
    "len_list_test *= file_count2\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "\n",
    "for audio_number in number_list_train:\n",
    "    Audio_train = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba/' + str(audio_number) + '.wav')\n",
    "    len_list_train[i] = int(len(Audio_train) / (1000))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "for audio_number in number_list_test:\n",
    "    Audio_test = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba_test/' + str(audio_number) + '.wav')\n",
    "    len_list_test[j] = int(len(Audio_test) / (1000))\n",
    "    j += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimun_audio_train = np.min(len_list_train)\n",
    "minimun_audio_test = np.min(len_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de los segmentos de audio para despues crear los espectogramas\n",
    "\n",
    "t1_train_ini = 20 * 1000\n",
    "t1_test_ini = 20 * 1000\n",
    "t2_train_end = 45 * 1000\n",
    "t2_test_end = 45 * 1000\n",
    "\n",
    "for audio_number in number_list_train:\n",
    "    Audio_train = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba/' + str(audio_number) + '.wav')\n",
    "    Audio_train = Audio_train[t1_train_ini:t2_train_end]\n",
    "    Audio_train.export('C:/Users/Fran/Desktop/database_train/' + str(audio_number) + '.wav', format=\"wav\")\n",
    "    \n",
    "    \n",
    "for audio_number in number_list_test:\n",
    "    Audio_test = AudioSegment.from_wav('C:/Users/Fran/Desktop/prueba_test/' + str(audio_number) + '.wav')\n",
    "    Audio_test = Audio_test[t1_train_ini:t2_train_end]\n",
    "    Audio_test.export('C:/Users/Fran/Desktop/database_test/' + str(audio_number) + '.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fran\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:960: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  warnings.warn('amplitude_to_db was called on complex input so phase '\n"
     ]
    }
   ],
   "source": [
    "#Spectograms of each segmented audio\n",
    "\n",
    "i = 0\n",
    "Xdb_train = ['']\n",
    "Xdb_train_normalized = ['']\n",
    "Xdb_train *= file_count\n",
    "Xdb_train_normalized *= file_count\n",
    "\n",
    "Xdb_test = ['']\n",
    "Xdb_test_normalized = ['']\n",
    "Xdb_test *= file_count2\n",
    "Xdb_test_normalized *= file_count2\n",
    "\n",
    "for audio_train in number_list_train:\n",
    "    X, sr = librosa.load('C:/Users/Fran/Desktop/database_train/' + str(audio_train) + '.wav')\n",
    "    Xdb_train[i] = inspect_data(X)\n",
    "    #Xdb_train_normalized[i] = tf.log(tf.abs(Xdb_train[i]) + 0.01)\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "\n",
    "for audio_test in number_list_test:\n",
    "    X, sr = librosa.load('C:/Users/Fran/Desktop/database_test/' + str(audio_test) + '.wav')\n",
    "    Xdb_test[i] = inspect_data(X)\n",
    "    #Xdb_test_normalized[i] = tf.log(tf.abs(Xdb_test[i]) + 0.01)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(Xdb_train_normalized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8614"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Espectograma de 1 audio segmentado\n",
    "\n",
    "plt.imshow(Xdb_train[0])\n",
    "alto, ancho = np.shape(Xdb_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 129, 10336)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 1, 1111206)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xdb_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phq8_array_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de los arrays, transformand el array para introducirlo en la red LSTM\n",
    "\n",
    "Xdb_train_array = np.ndarray(shape = (107,alto,ancho))\n",
    "Xdb_test_array = np.ndarray(shape = (35,alto,ancho))\n",
    "\n",
    "i = 0\n",
    "for train in Xdb_train:\n",
    "    Xdb_train_array[i] = train\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "for test in Xdb_test:\n",
    "    Xdb_test_array[i] = test\n",
    "    i += 1\n",
    "    \n",
    "Xdb_train_array = Xdb_train_array.reshape(107 ,alto*ancho)\n",
    "Xdb_test_array = Xdb_test_array.reshape(35, alto*ancho)\n",
    "\n",
    "Xdb_train_array = np.reshape(Xdb_train_array, (Xdb_train_array.shape[0], 1, Xdb_train_array.shape[1]))\n",
    "Xdb_test_array = np.reshape(Xdb_test_array, (Xdb_test_array.shape[0], 1, Xdb_test_array.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i= 0\n",
    "#for audio_train in number_list_train:\n",
    "#    Xdb_train[i] = Xdb_train[i].reshape(1333344,)\n",
    "#    i += 1\n",
    "    \n",
    "#i= 0    \n",
    "#for audio_test in number_list_test:\n",
    "#    Xdb_test[i] = Xdb_test[i].reshape(1333344,)\n",
    "#    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdb_train_array=Xdb_train_array.reshape(Xdb_train_array.shape[0],Xdb_train_array.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdb_test_array=Xdb_test_array.reshape(Xdb_test_array.shape[0],Xdb_test_array.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(Xdb_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes = 2\n",
    "#batch_size = 64\n",
    "#epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdb_train_array = Xdb_train_array.reshape(Xdb_train_array.shape[0], alto, ancho, 1)\n",
    "#Xdb_test_array = Xdb_test_array.reshape(Xdb_test_array.shape[0], alto, ancho, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (Xdb_train_array.shape)\n",
    "#print (Xdb_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq = Sequential()\n",
    "#seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "#                   input_shape=(107, 129, 1723, 1),\n",
    "#                   padding='same', return_sequences=True))\n",
    "#seq.add(BatchNormalization())\n",
    "\n",
    "#seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "#                   padding='same', return_sequences=True))\n",
    "#seq.add(BatchNormalization())\n",
    "\n",
    "#seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "#                   padding='same', return_sequences=True))\n",
    "#seq.add(BatchNormalization())\n",
    "\n",
    "#seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "#                   padding='same', return_sequences=True))\n",
    "#seq.add(BatchNormalization())\n",
    "\n",
    "#seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "#               activation='sigmoid',\n",
    "#               padding='same', data_format='channels_last'))\n",
    "#seq.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Red neuronal\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(alto,ancho,1)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "phq8_array_train = keras.utils.to_categorical(phq8_array_train, num_classes)\n",
    "phq8_array_test = keras.utils.to_categorical(phq8_array_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 1, 256)            1138007040\n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               164352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,138,179,778\n",
      "Trainable params: 1,138,179,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True),\n",
    "                        input_shape=(1, alto*ancho)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.rmsprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107 samples, validate on 35 samples\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 294s 3s/step - loss: 0.6664 - acc: 0.5794 - val_loss: 0.6504 - val_acc: 0.6571\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 257s 2s/step - loss: 0.6246 - acc: 0.7103 - val_loss: 0.6460 - val_acc: 0.6571\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 234s 2s/step - loss: 0.5965 - acc: 0.7196 - val_loss: 0.6538 - val_acc: 0.6571\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 266s 2s/step - loss: 0.5813 - acc: 0.7196 - val_loss: 0.6520 - val_acc: 0.6571\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 236s 2s/step - loss: 0.5951 - acc: 0.7196 - val_loss: 0.6733 - val_acc: 0.6571\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 286s 3s/step - loss: 0.6080 - acc: 0.7196 - val_loss: 0.6729 - val_acc: 0.6571\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 281s 3s/step - loss: 0.5972 - acc: 0.7196 - val_loss: 0.6434 - val_acc: 0.6571\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 250s 2s/step - loss: 0.6176 - acc: 0.7196 - val_loss: 0.6457 - val_acc: 0.6571\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 265s 2s/step - loss: 0.6068 - acc: 0.7196 - val_loss: 0.6438 - val_acc: 0.6571\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 273s 3s/step - loss: 0.6012 - acc: 0.7196 - val_loss: 0.6748 - val_acc: 0.6571\n",
      "Test loss: 0.6748288844312941\n",
      "Test accuracy: 0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xdb_train_array, phq8_array_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(Xdb_test_array, phq8_array_test))\n",
    "score = model.evaluate(Xdb_test_array, phq8_array_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phq8_array_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 3s 76ms/step\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7626601  0.23733997]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7613366  0.23866336]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7707407  0.22925933]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7606199  0.23938014]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7606951 0.2393049]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.76619846 0.23380156]\n",
      "Valor predicho: [0.7687864  0.23121361]\n",
      "Valor predicho: [0.7687864  0.23121361]\n"
     ]
    }
   ],
   "source": [
    "prediccion = model.predict(Xdb_test_array, batch_size=batch_size, verbose=1, steps=None)\n",
    "for i in prediccion:\n",
    "    print('Valor predicho:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_pred = ['']\n",
    "conf_matrix_pred *= 35\n",
    "j = 0\n",
    "for i in prediccion:\n",
    "    conf_matrix_pred[j] = i.argmax(axis=0)\n",
    "    print (\"Clase: \" + str(i.argmax(axis=0)))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 1\n",
      "Clase: 1\n",
      "Clase: 1\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 1\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n",
      "Clase: 0\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_test = ['']\n",
    "conf_matrix_test *= 35\n",
    "j = 0\n",
    "for i in phq8_array_test:\n",
    "    conf_matrix_test[j] = i.argmax(axis=0)\n",
    "    print (\"Clase: \" + str(i.argmax(axis=0)))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(conf_matrix_test,conf_matrix_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[23  0]\n",
      " [12  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=['No depresion','Depresion'],\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
